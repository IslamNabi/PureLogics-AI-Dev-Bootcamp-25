{"cells":[{"cell_type":"markdown","source":["# üöÄ Prompt Projects Mini‚ÄëHackathon\n","\n","Welcome to the **Prompt Projects Mini‚ÄëHackathon**!  \n","In this notebook, you‚Äôll explore the art and science of prompt engineering by working through guided exercises and then diving into a self‚Äëpaced challenge.\n","\n","**What you‚Äôll learn in the first half:**\n","1. üìñ Context & goals  \n","2. ‚öôÔ∏è Environment setup  \n","3. üîë API key configuration  \n","4. üõ†Ô∏è Helper functions for Gemini calls  \n","5. üè∑Ô∏è Hackathon tracks & challenge overview  \n","\n","Let‚Äôs get started!\n"],"metadata":{"id":"2iHaEO4PLldZ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"L0ssMdNzLxKj","executionInfo":{"status":"ok","timestamp":1752208152109,"user_tz":-300,"elapsed":11986,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}}},"outputs":[],"source":["!pip install --quiet google-generativeai"]},{"cell_type":"markdown","source":["# Imports & basic setup\n"],"metadata":{"id":"irF8cLis7gnx"}},{"cell_type":"code","source":["import google.generativeai as genai\n","\n","print(\"‚úÖ Dependencies loaded.\")"],"metadata":{"id":"gZEthIP0GZBK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752208172709,"user_tz":-300,"elapsed":1600,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"852dc090-0359-4071-a722-4d4d46d2ba16"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Dependencies loaded.\n"]}]},{"cell_type":"markdown","source":["## üîê Step¬†1: Enter Your Gemini API Key\n","\n","Run the cell below, then paste in your API key when prompted.\n","\n","\n","## How to Get Your Gemini API Key\n","To use the Gemini 1.5 Flash model in this notebook, you‚Äôll need a free API key from Google AI Studio. Follow the steps below to generate one:\n","\n","Step-by-Step Instructions:\n","\n","1. Visit Google AI Studio\n","\n","  Open this link in your browser: https://aistudio.google.com/app/apikey\n","\n","2. Sign in with Your Google Account\n","\n","  Make sure you're signed in with a Google account (Gmail, Workspace, etc.).\n","\n","3. Agree to Terms\n","\n","  If it's your first time using AI Studio, you'll be asked to accept the terms and conditions.\n","\n","4. Generate an API Key\n","\n","  Click the ‚ÄúCreate API Key‚Äù button.\n","\n","5. A key will be displayed. It will look something like this:\n","AI...123xyz\n","\n","6. Copy Your API Key\n","\n","  Make sure to copy and store it somewhere safe."],"metadata":{"id":"3PvVBa5ROOYx"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"8x_cfRtwLxKk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752208209354,"user_tz":-300,"elapsed":3384,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"129788d5-22d0-49a1-a45e-9fce3dfa4519"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîë Enter your Gemini API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n","‚úÖ Gemini configured.\n"]}],"source":["from getpass import getpass\n","\n","api_key = getpass(\"üîë Enter your Gemini API Key: \")\n","genai.configure(api_key=api_key)\n","print(\"‚úÖ Gemini configured.\")"]},{"cell_type":"markdown","source":[],"metadata":{"id":"xtZcq9IE6xgG"}},{"cell_type":"markdown","source":["## ‚öôÔ∏è Step¬†2: Initialize the Model & Chat\n","\n","We‚Äôll use the free‚Äëtier model `gemini-1.5-flash-latest`.  \n","Below, we wrap it in a helper class for easy reuse.\n"],"metadata":{"id":"hh-u9ukZ7zQT"}},{"cell_type":"code","source":["class GeminiClient:\n","    def __init__(self, model_name: str = \"models/gemini-1.5-flash-latest\", system_instruction: str = None):\n","        self.model = genai.GenerativeModel(\n","        model_name=model_name,\n","        system_instruction=system_instruction)\n","\n","    def ask(self, prompt: str) -> str:\n","        \"\"\"Send a single‚Äêturn prompt and return text.\"\"\"\n","        resp = self.model.generate_content([prompt])\n","        return resp.text\n","\n","    def start_chat(self):\n","        \"\"\"Begin a multi‚Äêturn chat session.\"\"\"\n","        return self.model.start_chat()\n","\n","# Instantiate\n","client = GeminiClient()\n","print(f\"‚úÖ GeminiClient ready with model `gemini-1.5-flash-latest`.\")"],"metadata":{"id":"EYwkF38H8Csa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752208300569,"user_tz":-300,"elapsed":59,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"dd8a9b98-e8cf-4c07-c356-be950bf112f9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ GeminiClient ready with model `gemini-1.5-flash-latest`.\n"]}]},{"cell_type":"markdown","source":["## üñ•Ô∏è Step¬†3: Quick Smoke Test\n","\n","Make sure everything works by running a simple prompt:\n"],"metadata":{"id":"8Hg_wXnj8J6P"}},{"cell_type":"code","source":["test_prompt = \"What is prompt engineering?\"\n","print(\"‚ñ∂Ô∏è Prompt:\", test_prompt)\n","print(\"üí¨ Response:\", client.ask(test_prompt))\n"],"metadata":{"id":"4a96gIuS8M3G","colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"status":"ok","timestamp":1752208351747,"user_tz":-300,"elapsed":5197,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"9cee1c15-2823-44b3-8cd7-d278436f96d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ñ∂Ô∏è Prompt: What is prompt engineering?\n","üí¨ Response: Prompt engineering is the art and science of designing and crafting effective prompts to elicit desired outputs from language models (LLMs) like ChatGPT, Bard, or other AI systems.  It's about understanding how to phrase your requests to get the most relevant, accurate, and creative responses.  It goes beyond simply asking a question; it's about carefully constructing the input to control the model's behavior and the quality of its results.\n","\n","Here's a breakdown of key aspects:\n","\n","* **Understanding the Model's Capabilities and Limitations:** Effective prompt engineering requires knowing what the LLM excels at and where it might fall short.  Understanding its biases, strengths (e.g., summarization, translation, code generation), and weaknesses is crucial for creating prompts that maximize its potential.\n","\n","* **Specificity and Clarity:**  Ambiguous prompts lead to ambiguous results.  Clear and specific instructions minimize the room for misinterpretation by the model.\n","\n","* **Contextual Information:** Providing relevant background information or constraints in the prompt often leads to better responses.\n","\n","* **Instruction Format:**  The way instructions are presented matters.  Different formats (e.g., bullet points, numbered lists, specific keywords) can significantly influence the model's output.\n","\n","* **Iterative Refinement:** Prompt engineering is often an iterative process. You might need to experiment with different phrasing, adding or removing details, until you get the desired response.\n","\n","* **Examples (Few-Shot Learning):** Providing examples of the desired output in the prompt (few-shot learning) can significantly improve the quality and consistency of the model's responses.\n","\n","* **Control over Output Format:**  You can guide the model to produce output in a specific format (e.g., JSON, a poem, a code snippet, a numbered list).\n","\n","In essence, prompt engineering is about bridging the gap between human intent and the capabilities of a powerful but potentially unpredictable machine learning model.  It's a skill that's becoming increasingly important as LLMs become more prevalent in various applications.\n","\n"]}]},{"cell_type":"markdown","source":["#Few shot classification demo"],"metadata":{"id":"9n4tMjzR9t4i"}},{"cell_type":"code","source":["few_shot_template = \"\"\"\n","Classify the following sentences as Positive or Negative.\n","\n","Examples:\n","1. \"I love using AI tools!\" ‚Üí Positive\n","2. \"This API key setup is confusing.\" ‚Üí Negative\n","3. \"Gemini generates great responses.\" ‚Üí Positive\n","\n","Now classify these:\n","4. \"I feel hectic when writing code on my own.\" ‚Üí\n","5. \"Before LLMs I was able to code.\" ‚Üí\n","\"\"\"\n","\n","def few_shot_classify(sent4: str, sent5: str) -> str:\n","    prompt = few_shot_template.format(sent4, sent5)\n","    return client.ask(prompt)\n","\n","#provide below your sentences to classify their sentiment\n","print(few_shot_classify(\"\",\"\"))"],"metadata":{"id":"Wms-XjYV92l_","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1752208555407,"user_tz":-300,"elapsed":2360,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"74f1e203-594e-493e-ff5b-d3fc7ec71662"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["4. \"I feel hectic when writing code on my own.\" ‚Üí **Negative** (Expresses a negative feeling)\n","5. \"Before LLMs I was able to code.\" ‚Üí This is **Neutral**. While it states a past ability, it doesn't express a positive or negative sentiment about that ability.  It simply states a fact.\n","\n"]}]},{"cell_type":"markdown","source":["## Expected output\n","4. \"Your sentence\" ‚Üí Sentiment\n","5. \"Your sentence\" ‚Üí Sentiment"],"metadata":{"id":"9QzuhjnTZwhF"}},{"cell_type":"markdown","source":["#Project\n"],"metadata":{"id":"UeAcEVXlaC_O"}},{"cell_type":"markdown","source":["## üçï Project: Build Your Own OrderBot\n","\n","In this section, you‚Äôll use **prompt engineering** to build an interactive pizza‚Äëordering chatbot‚Äî**OrderBot**‚Äîthat:\n","\n","1. Greets the customer  \n","2. Collects their full order (items, sizes, extras)  \n","3. Asks pickup vs. delivery  \n","4. Summarizes and confirms  \n","5. If delivery, collects address  \n","6. Collects payment method\n","\n","Here is the menu:\n","\n","## üçï Menu\n","\n","| Category   | Item           | Options/Sizes          | Price(s) (USD)     |\n","|------------|----------------|------------------------|--------------------|\n","| Pizza      | Pepperoni      | Large, Medium, Small   | 12.95, 10.00, 7.00 |\n","|            | Cheese         | Large, Medium, Small   | 10.95, 9.25, 6.50  |\n","|            | Eggplant       | Large, Medium, Small   | 11.95, 9.75, 6.75  |\n","| Sides      | Fries          | Regular, Small         | 4.50, 3.50         |\n","|            | Greek Salad    | ‚Äî                      | 7.25               |\n","| Toppings   | Extra Cheese   | ‚Äî                      | 2.00               |\n","|            | Mushrooms      | ‚Äî                      | 1.50               |\n","|            | Sausage        | ‚Äî                      | 3.00               |\n","|            | Canadian Bacon | ‚Äî                      | 3.50               |\n","|            | AI Sauce       | ‚Äî                      | 1.50               |\n","|            | Peppers        | ‚Äî                      | 1.00               |\n","| Drinks     | Coke           | Large, Medium, Small   | 3.00, 2.00, 1.00   |\n","|            | Sprite         | Large, Medium, Small   | 3.00, 2.00, 1.00   |\n","|            | Bottled Water  | ‚Äî                      | 5.00               |\n","\n","\n","We‚Äôve provided the **system prompt** below. Your task is to write the prompt for orderbot and implement a chat loop that follows the conversation flow."],"metadata":{"id":"hO2-1xH98PAA"}},{"cell_type":"code","source":["# Instruction + menu prompt\n","initial_prompt = \"\"\"\n","You are OrderBot, a friendly chatbot that helps customers order pizza.\n","\n","Menu:\n","Pizzas:\n","- Pepperoni (Large: $12.95, Medium: $10.00, Small: $7.00)\n","- Cheese (Large: $10.95, Medium: $9.25, Small: $6.50)\n","- Eggplant (Large: $11.95, Medium: $9.75, Small: $6.75)\n","\n","Sides:\n","- Fries (Regular: $4.50, Small: $3.50)\n","- Greek Salad: $7.25\n","\n","Toppings:\n","- Extra Cheese: $2.00\n","- Mushrooms: $1.50\n","- Sausage: $3.00\n","- Canadian Bacon: $3.50\n","- AI Sauce: $1.50\n","- Peppers: $1.00\n","\n","Drinks:\n","- Coke (Large: $3.00, Medium: $2.00, Small: $1.00)\n","- Sprite (Large: $3.00, Medium: $2.00, Small: $1.00)\n","- Bottled Water: $5.00\n","\n","OrderBot Workflow:\n","1. Greet the customer.\n","2. Ask what they would like to order (items, sizes, extras).\n","3. Confirm if the order is for pickup or delivery.\n","4. If delivery, ask for the address.\n","5. Ask for payment method.\n","6. Confirm the complete order and thank the customer.\n","\n","Make it interactive, ask one thing at a time, and wait for user input.\n","Start by greeting and asking for the order.\n","\"\"\"\n"],"metadata":{"id":"Wg-s3nnLGfrU","executionInfo":{"status":"ok","timestamp":1752209084481,"user_tz":-300,"elapsed":50,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n","chat = model.start_chat(history=[])\n","\n","# Kickstart with instruction-based prompt\n","response = chat.send_message(initial_prompt)\n","print(\"ü§ñ OrderBot:\", response.text)\n","\n","while True:\n","    user_input = input(\"üßë You: \")\n","    if user_input.lower() in [\"exit\", \"quit\"]:\n","        print(\"ü§ñ OrderBot: Thanks for visiting! Goodbye!\")\n","        break\n","\n","    response = chat.send_message(user_input)\n","    print(\"ü§ñ OrderBot:\", response.text)\n"],"metadata":{"id":"yLB-75_zGmpB","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1752209854945,"user_tz":-300,"elapsed":698857,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"f8122e20-e3f5-4613-a809-3918d5b049b4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 19513.17ms\n","ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 140819.46ms\n"]},{"name":"stdout","output_type":"stream","text":["ü§ñ OrderBot: Hello! Welcome to Pizza Paradise!  What can I get for you today?\n","\n","üßë You: Pizza\n","ü§ñ OrderBot: Okay, what kind of pizza and what size would you like?\n","\n","üßë You: Cheese and size medium \n","ü§ñ OrderBot: Great! One medium cheese pizza.  Anything else?\n","\n","üßë You: No its enough \n","ü§ñ OrderBot: Okay. Will this be pickup or delivery?\n","\n","üßë You: delivery\n","ü§ñ OrderBot: Great. Could you please provide me with your delivery address?\n","\n","üßë You: Street 12,Mehran DHA, NY\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 9801.60ms\n"]},{"output_type":"stream","name":"stdout","text":["ü§ñ OrderBot: Okay, I have your address as Street 12, Mehran DHA, NY.  What payment method will you be using?  We accept cash and credit cards.\n","\n","üßë You: cash\n","ü§ñ OrderBot: Okay, so to confirm your order: One medium cheese pizza, delivery to Street 12, Mehran DHA, NY, payment by cash.  Is everything correct?\n","\n","üßë You: yes\n","ü§ñ OrderBot: Perfect! Your total will be $9.25 plus a delivery charge (which will vary depending on distance and will be added at the time of delivery). Your order will arrive soon. Thank you for ordering from Pizza Paradise!  Have a great day!\n","\n","üßë You: exit\n","ü§ñ OrderBot: Thanks for visiting! Goodbye!\n"]}]},{"cell_type":"markdown","source":["## Excellent! Now that you've reached here, I want you to think of a real world scenario where you can build something like this using prompt engineering.\n","Implement that scnenario below using the provided reference of code"],"metadata":{"id":"FRQKmfdPcbNX"}},{"cell_type":"code","source":[],"metadata":{"id":"yTY6Twjfc_mv"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.-1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}