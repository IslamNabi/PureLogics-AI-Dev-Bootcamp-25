{"cells":[{"cell_type":"markdown","source":["#Introduction to TensorFlow"],"metadata":{"id":"pAueO1JuEyX1"},"id":"pAueO1JuEyX1"},{"cell_type":"markdown","source":["# üìò TensorFlow Basics\n","\n","TensorFlow is a powerful open-source library developed by Google for deep learning and numerical computation. It uses dataflow graphs and automatic differentiation to perform optimized computations.\n","\n","Let's get started by learning how to use Tensors, which are the fundamental building blocks of TensorFlow.\n"],"metadata":{"id":"0Zje9pmGEZ39"},"id":"0Zje9pmGEZ39"},{"cell_type":"markdown","source":["##Installing and Importing TensorFlow"],"metadata":{"id":"gZzCJOKfE6em"},"id":"gZzCJOKfE6em"},{"cell_type":"code","execution_count":2,"id":"f94b4684-18a0-4b8f-a208-c4cccd8e3df4","metadata":{"id":"f94b4684-18a0-4b8f-a208-c4cccd8e3df4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749721735968,"user_tz":-300,"elapsed":13402,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"f0e96a84-cb82-42bd-ac0f-02c5a457c058"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.18.0\n"]}],"source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)\n"]},{"cell_type":"markdown","source":["## üì¶ Tensors\n","\n","Tensors are multi-dimensional arrays (like NumPy arrays). TensorFlow supports scalar (0D), vector (1D), matrix (2D), and higher dimensional tensors.\n","\n","Let's see how to create and inspect them.\n"],"metadata":{"id":"3pwCFcNIEeZs"},"id":"3pwCFcNIEeZs"},{"cell_type":"markdown","source":["##Tensor Creation and Attributes"],"metadata":{"id":"cOSjm00qE-ff"},"id":"cOSjm00qE-ff"},{"cell_type":"code","execution_count":3,"id":"48682690-fec9-4a35-a36a-f6b8d4976c2e","metadata":{"id":"48682690-fec9-4a35-a36a-f6b8d4976c2e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749721835101,"user_tz":-300,"elapsed":28,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"f7ed7748-0568-43e9-b145-5e2758b7c183"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scalar: tf.Tensor(7, shape=(), dtype=int32)\n","Vector: tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n","Matrix:\n"," tf.Tensor(\n","[[1 2]\n"," [3 4]], shape=(2, 2), dtype=int32)\n","Shape: (2, 2)\n","Data Type: <dtype: 'int32'>\n"]}],"source":["# Scalar\n","scalar = tf.constant(7)\n","print(\"Scalar:\", scalar)\n","\n","# Vector\n","vector = tf.constant([1.0, 2.0, 3.0])\n","print(\"Vector:\", vector)\n","\n","# Matrix\n","matrix = tf.constant([[1, 2], [3, 4]])\n","print(\"Matrix:\\n\", matrix)\n","\n","# Check shape and dtype\n","print(\"Shape:\", matrix.shape)\n","print(\"Data Type:\", matrix.dtype)\n"]},{"cell_type":"markdown","source":["## ‚ûï Tensor Operations\n","\n","TensorFlow supports element-wise operations like addition, multiplication, matrix multiplication, etc.\n"],"metadata":{"id":"SqsPFQWxEl9f"},"id":"SqsPFQWxEl9f"},{"cell_type":"markdown","source":["##Tensor Arithmetic"],"metadata":{"id":"mzKgAZG2FFtx"},"id":"mzKgAZG2FFtx"},{"cell_type":"code","execution_count":4,"id":"9d97dfa3-c982-4f0b-b48a-9bd4be4cf96f","metadata":{"id":"9d97dfa3-c982-4f0b-b48a-9bd4be4cf96f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722045742,"user_tz":-300,"elapsed":37,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"29d529f4-50f8-440d-996b-38dbb723fa89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Addition:\n"," tf.Tensor(\n","[[ 6  8]\n"," [10 12]], shape=(2, 2), dtype=int32)\n","Element-wise Multiplication:\n"," tf.Tensor(\n","[[ 5 12]\n"," [21 32]], shape=(2, 2), dtype=int32)\n","Matrix Multiplication:\n"," tf.Tensor(\n","[[19 22]\n"," [43 50]], shape=(2, 2), dtype=int32)\n"]}],"source":["a = tf.constant([[1, 2], [3, 4]])\n","b = tf.constant([[5, 6], [7, 8]])\n","\n","# Addition\n","print(\"Addition:\\n\", tf.add(a, b))\n","\n","# Multiplication (element-wise)\n","print(\"Element-wise Multiplication:\\n\", tf.multiply(a, b))\n","\n","# Matrix multiplication\n","print(\"Matrix Multiplication:\\n\", tf.matmul(a, b))\n"]},{"cell_type":"markdown","source":["# üèóÔ∏è Building a Neural Network with TensorFlow (Keras)\n","\n","We'll use `tf.keras`, a high-level API for building and training models. Let's train a simple neural network to classify digits using the MNIST dataset.\n"],"metadata":{"id":"1oed5gKvEp-Z"},"id":"1oed5gKvEp-Z"},{"cell_type":"markdown","source":["##Load Dataset and Normalize"],"metadata":{"id":"QvLBMh51FrCg"},"id":"QvLBMh51FrCg"},{"cell_type":"code","execution_count":5,"id":"c6fed9a6-7806-4644-8ea0-a4f251a82300","metadata":{"id":"c6fed9a6-7806-4644-8ea0-a4f251a82300","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722085324,"user_tz":-300,"elapsed":929,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"e912c453-cc2c-47ed-fa67-c85b4b655007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize to [0, 1]\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n"]},{"cell_type":"code","source":["print(x_train.shape)"],"metadata":{"id":"QicLWmL-KDV0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722181393,"user_tz":-300,"elapsed":7,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"10608bad-7ec0-4e18-f92f-210fdbf163e4"},"id":"QicLWmL-KDV0","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28)\n"]}]},{"cell_type":"markdown","source":["##Define a Model\n"],"metadata":{"id":"eh-EyLCjFuFT"},"id":"eh-EyLCjFuFT"},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Input layer\n","    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer\n","    tf.keras.layers.Dense(10, activation='softmax') # Output layer\n","])\n"],"metadata":{"id":"3jCh0KKkFz9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722279434,"user_tz":-300,"elapsed":48,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"49d7c92b-1bd5-4a26-abb8-40f9d4cf8e1f"},"id":"3jCh0KKkFz9W","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}]},{"cell_type":"markdown","source":["##Compile and Train"],"metadata":{"id":"h4qjHSsLF1qI"},"id":"h4qjHSsLF1qI"},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=5)\n"],"metadata":{"id":"EUbRUw_vF4FM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722395600,"user_tz":-300,"elapsed":45616,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"394ecd04-f0eb-4b7c-9639-f83541b0d4a5"},"id":"EUbRUw_vF4FM","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0591\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0429\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0340\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0257\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0223\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7eac31c50e50>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["##Evaluate the Model"],"metadata":{"id":"yY0A1y2QF5ki"},"id":"yY0A1y2QF5ki"},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(\"\\nTest Accuracy:\", test_acc)\n"],"metadata":{"id":"5-ZyN0kPF7uc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722419425,"user_tz":-300,"elapsed":958,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"5afb6204-5826-4767-9bc3-e6b7a4b08e8b"},"id":"5-ZyN0kPF7uc","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0856\n","\n","Test Accuracy: 0.9807000160217285\n"]}]},{"cell_type":"markdown","source":["#1. Understand the Basic Syntax and Operations (PyTorch)"],"metadata":{"id":"-Cg4QxfkGuEM"},"id":"-Cg4QxfkGuEM"},{"cell_type":"markdown","source":["# Introduction to PyTorch\n","## üî• PyTorch Basics\n","\n","PyTorch is a popular open-source deep learning library developed by Facebook AI. It provides flexibility and speed through dynamic computation graphs and strong GPU support.\n","\n","In this section, we'll start by exploring how PyTorch handles tensors and automatic differentiation.\n"],"metadata":{"id":"WJPRbwIpG1fq"},"id":"WJPRbwIpG1fq"},{"cell_type":"markdown","source":["##Installing and Importing PyTorch"],"metadata":{"id":"rW20lq7SHAGu"},"id":"rW20lq7SHAGu"},{"cell_type":"code","source":["import torch\n","print(\"PyTorch version:\", torch.__version__)\n"],"metadata":{"id":"uSkivCN8G3xf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722525355,"user_tz":-300,"elapsed":7728,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"aa0629d9-3c33-4f73-e101-c0b447ad757e"},"id":"uSkivCN8G3xf","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.6.0+cu124\n"]}]},{"cell_type":"markdown","source":["##Creating and Inspecting Tensors\n","## üì¶ Tensors in PyTorch\n","\n","Tensors are multidimensional arrays, just like in NumPy. They're the building blocks of PyTorch and support operations like addition, multiplication, reshaping, etc.\n"],"metadata":{"id":"t3zTi5TkHDNf"},"id":"t3zTi5TkHDNf"},{"cell_type":"markdown","source":["##Tensor Creation and Properties"],"metadata":{"id":"xx1C8pwGHJDZ"},"id":"xx1C8pwGHJDZ"},{"cell_type":"code","source":["# Scalar\n","scalar = torch.tensor(5)\n","print(\"Scalar:\", scalar)\n","\n","# Vector\n","vector = torch.tensor([1.0, 2.0, 3.0])\n","print(\"Vector:\", vector)\n","\n","# Matrix\n","matrix = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n","print(\"Matrix:\\n\", matrix)\n","\n","# Shape and data type\n","print(\"Shape:\", matrix.shape)\n","print(\"Data Type:\", matrix.dtype)\n"],"metadata":{"id":"joNmA_2KHK3-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722582657,"user_tz":-300,"elapsed":137,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"ca937e3f-afbf-45b2-98c3-476fef6a512a"},"id":"joNmA_2KHK3-","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Scalar: tensor(5)\n","Vector: tensor([1., 2., 3.])\n","Matrix:\n"," tensor([[1., 2.],\n","        [3., 4.]])\n","Shape: torch.Size([2, 2])\n","Data Type: torch.float32\n"]}]},{"cell_type":"markdown","source":["## ‚ûï Tensor Operations\n","\n","PyTorch supports common element-wise operations as well as matrix multiplication, reshaping, and broadcasting.\n"],"metadata":{"id":"lNNOpA_kHMEY"},"id":"lNNOpA_kHMEY"},{"cell_type":"markdown","source":["##Tensor Arithmetic"],"metadata":{"id":"gonKamu_HSO2"},"id":"gonKamu_HSO2"},{"cell_type":"code","source":["a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n","b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n","\n","# Addition\n","print(\"Addition:\\n\", a + b)\n","\n","# Element-wise multiplication\n","print(\"Element-wise Multiplication:\\n\", a * b)\n","\n","# Matrix multiplication\n","print(\"Matrix Multiplication:\\n\", torch.matmul(a, b))\n"],"metadata":{"id":"_9NAKgDKHQvk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722748780,"user_tz":-300,"elapsed":46,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"e3484d3c-a2a6-42c9-e8d7-dd7f4b1459b1"},"id":"_9NAKgDKHQvk","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Addition:\n"," tensor([[ 6.,  8.],\n","        [10., 12.]])\n","Element-wise Multiplication:\n"," tensor([[ 5., 12.],\n","        [21., 32.]])\n","Matrix Multiplication:\n"," tensor([[19., 22.],\n","        [43., 50.]])\n"]}]},{"cell_type":"markdown","source":["# üèóÔ∏è Building a Neural Network with PyTorch\n","\n","Now let's build a simple neural network to classify digits from the MNIST dataset using `torch.nn` and `torch.optim`.\n"],"metadata":{"id":"njWuzq0hHVbs"},"id":"njWuzq0hHVbs"},{"cell_type":"markdown","source":["##Load and Normalize MNIST Dataset"],"metadata":{"id":"AcM1IQqSHZgC"},"id":"AcM1IQqSHZgC"},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Transform: Normalize to [0, 1]\n","transform = transforms.ToTensor()\n","\n","train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"],"metadata":{"id":"Nx5gFsBAHUQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722793046,"user_tz":-300,"elapsed":9661,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"44b7fc06-7f9f-45e1-8820-81275a6296b0"},"id":"Nx5gFsBAHUQy","execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 53.5MB/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 1.77MB/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 12.9MB/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 5.02MB/s]\n"]}]},{"cell_type":"markdown","source":["##Define Neural Network"],"metadata":{"id":"J6wJF3tRHe8c"},"id":"J6wJF3tRHe8c"},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)  # Flatten\n","        x = F.relu(self.fc1(x))\n","        return F.log_softmax(self.fc2(x), dim=1)\n","\n","model = SimpleNN()\n"],"metadata":{"id":"HqwXBPFRHhTu","executionInfo":{"status":"ok","timestamp":1749722822756,"user_tz":-300,"elapsed":49,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}}},"id":"HqwXBPFRHhTu","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["##Define Loss and Optimizer"],"metadata":{"id":"4niFyUCDHitt"},"id":"4niFyUCDHitt"},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"-OVaPDUgHkfQ","executionInfo":{"status":"ok","timestamp":1749722829716,"user_tz":-300,"elapsed":7,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}}},"id":"-OVaPDUgHkfQ","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["##Train the Model"],"metadata":{"id":"VABGEt4FHlZ9"},"id":"VABGEt4FHlZ9"},{"cell_type":"code","source":["epochs = 3\n","for epoch in range(epochs):\n","    for images, labels in train_loader:\n","        optimizer.zero_grad()\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"],"metadata":{"id":"c1p1qVh1HmyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722864413,"user_tz":-300,"elapsed":30153,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"2700911b-0771-4cdb-c85b-ab71439eb314"},"id":"c1p1qVh1HmyT","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.2931\n","Epoch 2, Loss: 0.0522\n","Epoch 3, Loss: 0.0889\n"]}]},{"cell_type":"markdown","source":["##Evaluate Accuracy"],"metadata":{"id":"pG05-tpQHnyF"},"id":"pG05-tpQHnyF"},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Test Accuracy: {correct / total * 100:.2f}%\")\n"],"metadata":{"id":"v8KGI5XOHpQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749722911454,"user_tz":-300,"elapsed":1235,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"f897332a-88e9-431a-89c6-116ff315b76f"},"id":"v8KGI5XOHpQy","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 96.75%\n"]}]},{"cell_type":"markdown","source":["#3. Compare Similarities and Differences with TensorFlow\n","\n","\n","# PyTorch vs TensorFlow: Quick Comparison\n","\n","| Feature                | PyTorch                               | TensorFlow                           |\n","|------------------------|----------------------------------------|--------------------------------------|\n","| Execution Mode         | Eager (Dynamic)                        | Eager (Static with option for Graph) |\n","| High-Level API         | `torch.nn`, `torch.optim`              | `tf.keras`                           |\n","| Dataset Loader         | `DataLoader`                           | `tf.data.Dataset`                    |\n","| Training Loop Style    | Mostly manual                          | `model.fit()` or manual              |\n","| Model Saving           | `torch.save()`                         | `model.save()` or `SavedModel`       |\n","| Visualization Tool     | TensorBoard (via `torch.utils.tensorboard`) | TensorBoard                    |\n","| Autograd Support       | Built-in via `autograd`                | `tf.GradientTape()`                  |\n","\n","Both libraries are capable of building state-of-the-art models. Your choice depends on project needs and comfort with syntax.\n"],"metadata":{"id":"GnMIxKhOHwg8"},"id":"GnMIxKhOHwg8"},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------"],"metadata":{"id":"pnLm3nWUNetE"},"id":"pnLm3nWUNetE"},{"cell_type":"markdown","source":["#Activity\n","\n","Create two custom models, one with Tensorflow and the other with Pytorch.\n","The models should have\n","\n","###  Model Architecture (Same for Both Frameworks)\n","\n","| Layer Type         | Configuration                      |\n","|--------------------|-------------------------------------|\n","| Input Layer        | Flatten (28√ó28 ‚Üí 784)              |\n","| Dense Layer 1      | 256 units, ReLU                    |\n","| Dropout Layer      | 30% (rate = 0.3)                   |\n","| Dense Layer 2      | 128 units, Tanh                    |\n","| Output Layer       | 10 units, Softmax (TF) / LogSoftmax (PT) |\n","\n","###  Instructions\n","\n","- Implement this architecture using `tf.keras.Sequential` in TensorFlow.\n","- Implement the same architecture using `torch.nn.Module` in PyTorch.\n","- Train both models for **5 epochs** using the **Adam optimizer** and an appropriate classification loss.\n","- Evaluate accuracy on the MNIST test set.\n"],"metadata":{"id":"S7tqweavLejs"},"id":"S7tqweavLejs"},{"cell_type":"code","source":["# TensorFlow Implementation\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","# Load and preprocess data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0, 1]\n","\n","# Create model\n","tf_model = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(256, activation='relu'),\n","    Dropout(0.3),\n","    Dense(128, activation='tanh'),\n","    Dense(10, activation='softmax')\n","])\n","\n","# Compile model\n","tf_model.compile(optimizer=Adam(),\n","                 loss=SparseCategoricalCrossentropy(),\n","                 metrics=['accuracy'])\n","\n","# Train model\n","print(\"Training TensorFlow model...\")\n","tf_history = tf_model.fit(x_train, y_train,\n","                          epochs=5,\n","                          validation_data=(x_test, y_test))\n","\n","# Evaluate model\n","tf_test_loss, tf_test_acc = tf_model.evaluate(x_test, y_test, verbose=0)\n","print(f\"\\nTensorFlow Model Test Accuracy: {tf_test_acc:.4f}\")"],"metadata":{"id":"z3oO-1OHL6zB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749723449264,"user_tz":-300,"elapsed":91773,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"45fbefc8-bc83-4479-92e6-374da579c2d9"},"id":"z3oO-1OHL6zB","execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Training TensorFlow model...\n","Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.3956 - val_accuracy: 0.9595 - val_loss: 0.1277\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.1230 - val_accuracy: 0.9736 - val_loss: 0.0880\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 0.0907 - val_accuracy: 0.9724 - val_loss: 0.0864\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0772 - val_accuracy: 0.9764 - val_loss: 0.0745\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0711 - val_accuracy: 0.9783 - val_loss: 0.0661\n","\n","TensorFlow Model Test Accuracy: 0.9783\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load and preprocess data\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","\n","# Create model\n","class PyTorchModel(nn.Module):\n","    def __init__(self):\n","        super(PyTorchModel, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.dense1 = nn.Linear(28*28, 256)\n","        self.dropout = nn.Dropout(0.3)\n","        self.dense2 = nn.Linear(256, 128)\n","        self.output = nn.Linear(128, 10)\n","        self.log_softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = torch.relu(self.dense1(x))\n","        x = self.dropout(x)\n","        x = torch.tanh(self.dense2(x))\n","        x = self.log_softmax(self.output(x))\n","        return x\n","\n","pt_model = PyTorchModel().to(device)\n","optimizer = optim.Adam(pt_model.parameters())\n","criterion = nn.NLLLoss()  # Negative Log Likelihood Loss for LogSoftmax\n","\n","# Training function\n","def train(model, device, train_loader, optimizer, criterion, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","# Test function\n","def test(model, device, test_loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    return correct / len(test_loader.dataset)\n","\n","# Train and evaluate\n","print(\"\\nTraining PyTorch model...\")\n","for epoch in range(1, 6):\n","    train(pt_model, device, train_loader, optimizer, criterion, epoch)\n","    test_acc = test(pt_model, device, test_loader)\n","    print(f'Epoch {epoch}, Test Accuracy: {test_acc:.4f}')\n","\n","final_test_acc = test(pt_model, device, test_loader)\n","print(f\"\\nPyTorch Model Final Test Accuracy: {final_test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sn--tx5to5_A","executionInfo":{"status":"ok","timestamp":1749723598615,"user_tz":-300,"elapsed":107705,"user":{"displayName":"IslamNabi","userId":"15268998542759672787"}},"outputId":"1db84d66-9006-4d51-f62d-958774967cd8"},"id":"sn--tx5to5_A","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training PyTorch model...\n","Epoch 1, Test Accuracy: 0.9615\n","Epoch 2, Test Accuracy: 0.9719\n","Epoch 3, Test Accuracy: 0.9745\n","Epoch 4, Test Accuracy: 0.9753\n","Epoch 5, Test Accuracy: 0.9791\n","\n","PyTorch Model Final Test Accuracy: 0.9791\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LEz3rMJupakB"},"id":"LEz3rMJupakB","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}